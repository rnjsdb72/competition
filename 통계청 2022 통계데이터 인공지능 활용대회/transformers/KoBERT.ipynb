{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BjAf0E3L1UEU"},"outputs":[],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch\n","\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YENakCJv3Osf"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pylab as plt\n","%matplotlib inline\n","plt.rc('font', family='malgun gothic')\n","plt.rc('axes', unicode_minus=False)\n","import seaborn as sns\n","import os\n","import re\n","import missingno as msno\n","import pickle\n","from glob import glob\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","from sklearn.model_selection import train_test_split\n","\n","#kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649656085183,"user":{"displayName":"권유진","userId":"17694849594474805342"},"user_tz":-540},"id":"1_ptyW823Rvu","outputId":"d3568033-a4e7-4d77-ce32-908f34ee759b"},"outputs":[],"source":["if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    print(torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11470,"status":"ok","timestamp":1649656096649,"user":{"displayName":"권유진","userId":"17694849594474805342"},"user_tz":-540},"id":"EyubEdR03bOu","outputId":"c850328f-4c23-4a26-8fd3-96fbe9c9679a"},"outputs":[],"source":["#BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5arKg1CC3dFb"},"outputs":[],"source":["files = glob('/content/drive/MyDrive/공모전/data/*.txt')\n","for i, file in enumerate(files):\n","    globals()[f'file{i}'] = pd.read_table(file, sep='|', encoding='cp949')\n","code = pd.read_excel('/content/drive/MyDrive/공모전/data/한국표준산업분류(10차)_국문.xlsx', header = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILTfskI13gU8"},"outputs":[],"source":["idx2label_digit1 = dict(enumerate(sorted(file0.digit_1.unique())))\n","label2idx_digit1 = {label:idx for idx, label in enumerate(sorted(file0.digit_1.unique()))}\n","idx2label_digit2 = dict(enumerate(sorted(file0.digit_2.unique())))\n","label2idx_digit2 = {label:idx for idx, label in enumerate(sorted(file0.digit_2.unique()))}\n","idx2label_digit3 = dict(enumerate(sorted(file0.digit_3.unique())))\n","label2idx_digit3 = {label:idx for idx, label in enumerate(sorted(file0.digit_3.unique()))}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLEaqkBq3heh"},"outputs":[],"source":["file0['digit_1'] = file0['digit_1'].map(lambda x: label2idx_digit1[x])\n","file0['digit_2'] = file0['digit_2'].map(lambda x: label2idx_digit2[x])\n","file0['digit_3'] = file0['digit_3'].map(lambda x: label2idx_digit3[x])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bp786dft34lz"},"outputs":[],"source":["# 한 문장으로 합치기 때문에 공백으로 결측값 치환\n","file0 = file0.fillna(\"\")\n","file1 = file1.fillna(\"\")\n","\n","# 한 문장으로 합치기\n","file0[\"sen\"] = file0[\"text_obj\"] + \" \" + file0[\"text_mthd\"] + \" \" + file0[\"text_deal\"]\n","file1[\"sen\"] = file1[\"text_obj\"] + \" \" + file1[\"text_mthd\"] + \" \" + file1[\"text_deal\"]\n","\n","# 합친 문장 양쪽 공백 제거\n","file0[\"sen\"] = file0[\"sen\"].apply(lambda x : x.strip())\n","file1[\"sen\"] = file1[\"sen\"].apply(lambda x : x.strip())\n","\n","# digit_ 1, 2, 3 항목명 dataframe 만들어놓기\n","digit1_df = code.loc[3:][code[0].isnull() == False][[0, 1]].reset_index(drop = True).rename(columns = {0 : \"digit_1\", 1 : \"digit_1_text\"})\n","digit2_df = code.loc[3:][code[2].isnull() == False][[2, 3]].reset_index(drop = True).rename(columns = {2 : \"digit_2\", 3 : \"digit_2_text\"})\n","digit3_df = code.loc[3:][code[4].isnull() == False][[4, 5]].reset_index(drop = True).rename(columns = {4 : \"digit_3\", 5 : \"digit_3_text\"})\n","\n","# digit_1 항목명 뒤의 특수기호+숫자 제거\n","digit1_df[\"digit_1_text\"] = digit1_df[\"digit_1_text\"].apply(lambda x : x.split(\"(\")[0])"]},{"cell_type":"markdown","metadata":{"id":"2XwNaIY95RHA"},"source":["### Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VDPwLVE5Spo"},"outputs":[],"source":["# BERT에 넣을 DATASET 만드는 클래스\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bszaQHQo4_xW"},"outputs":[],"source":["data_digit1 = list(zip(file0['sen'], file0['digit_1']))\n","train_set, val_set = train_test_split(data_digit1, test_size=0.3, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZ0kz9A15WHI"},"outputs":[],"source":["# Setting parameters\n","max_len = 64\n","batch_size = 16\n","warmup_ratio = 0.1\n","num_epochs = 2\n","max_grad_norm = 1\n","log_interval = 400\n","learning_rate =  5e-5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52297,"status":"ok","timestamp":1649656159056,"user":{"displayName":"권유진","userId":"17694849594474805342"},"user_tz":-540},"id":"pYGW3QQx5ZHg","outputId":"9e04ab5e-295c-4a42-e2bb-d0ac761c7844"},"outputs":[],"source":["#토큰화 및 dataload\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","data_train = BERTDataset(train_set, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(val_set, 0, 1, tok, max_len, True, False)\n","\n","print(data_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbVWLBFP5ZFJ"},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size)\n","val_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"h1fN4oCH6pLn"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQLVSjI26p_b"},"outputs":[],"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=19,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VqG2EoCq6sgj"},"outputs":[],"source":["model1 = torch.load('/content/drive/MyDrive/공모전/models/kobert_digit_1_model.pt').to(device)\n","model2 = torch.load('/content/drive/MyDrive/공모전/models/kobert_digit_2_model.pt').to(device)\n","model3 = torch.load('/content/drive/MyDrive/공모전/models/kobert_digit_3_model.pt').to(device)"]},{"cell_type":"markdown","metadata":{"id":"NCYiHEbl6B5q"},"source":["### Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNWnUg0s6Cug"},"outputs":[],"source":["def predict(model, dataloader):\n","    model.eval()\n","    preds = []\n","    for batch in dataloader:\n","        batch1, batch2, batch3 = tuple(t.long().to(device) for t in batch)\n","        with torch.no_grad():\n","            pred = model(batch1, batch2, batch3)\n","            pred = pred.max(1, keepdim=True)[1]\n","            preds.append(pred)\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESUoqxR-6MqW"},"outputs":[],"source":["batch_size = 16\n","\n","valid_set = val_dataloader.dataset.sentences\n","valid_loader = DataLoader(\n","            valid_set,\n","            sampler = SequentialSampler(valid_set),\n","            batch_size = batch_size\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P-AuBqb76Iap"},"outputs":[],"source":["preds_digit1_val = torch.cat(predict(model1, valid_loader),axis=0).squeeze()\n","preds_digit2_val = torch.cat(predict(model2, valid_loader),axis=0).squeeze()\n","preds_digit3_val = torch.cat(predict(model3, valid_loader),axis=0).squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQcB-ygm6b87"},"outputs":[],"source":["val_preds = pd.DataFrame({'digit_1':preds_digit1_val.tolist(), 'digit_2':preds_digit2_val.tolist(), 'digit_3':preds_digit3_val.tolist()})\n","val_preds.to_csv('/content/drive/MyDrive/공모전/submissions/val_preds_kobert0409', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuGfAY_huaX2"},"outputs":[],"source":["def predict_proba(model, dataloader):\n","    model.eval()\n","    preds = []\n","    for batch in dataloader:\n","        batch1, batch2, batch3 = tuple(t.long().to(device) for t in batch)\n","        with torch.no_grad():\n","            pred = model(batch1, batch2, batch3)\n","            preds.append(pred)\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uq3VqGY0ubW8"},"outputs":[],"source":["batch_size = 16\n","\n","train_set = train_dataloader.dataset.sentences\n","train_loader = DataLoader(\n","            train_set,\n","            sampler = SequentialSampler(train_set),\n","            batch_size = batch_size\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxBqC4NtuhhM"},"outputs":[],"source":["proba_digit1_train = torch.cat(predict_proba(model1, train_loader),axis=0).cpu().numpy()\n","proba_digit2_train = torch.cat(predict_proba(model2, train_loader),axis=0).cpu().numpy()\n","proba_digit3_train = torch.cat(predict_proba(model3, train_loader),axis=0).cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPG6WMNBOaRJ"},"outputs":[],"source":["batch_size = 16\n","\n","valid_set = val_dataloader.dataset.sentences\n","valid_loader = DataLoader(\n","            valid_set,\n","            sampler = SequentialSampler(valid_set),\n","            batch_size = batch_size\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GbLtUadJu7Ym"},"outputs":[],"source":["proba_digit1_valid = torch.cat(predict_proba(model1, valid_loader),axis=0).cpu().numpy()\n","proba_digit2_valid = torch.cat(predict_proba(model2, valid_loader),axis=0).cpu().numpy()\n","proba_digit3_valid = torch.cat(predict_proba(model3, valid_loader),axis=0).cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"G-XRJx7kvXMN"},"outputs":[],"source":["np.save('/content/drive/MyDrive/공모전/submissions/train_proba1_kobert0409', proba_digit1_train)\n","np.save('/content/drive/MyDrive/공모전/submissions/train_proba2_kobert0409', proba_digit2_train)\n","np.save('/content/drive/MyDrive/공모전/submissions/train_proba3_kobert0409', proba_digit3_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"l69rUTaSvb2r"},"outputs":[],"source":["np.save('/content/drive/MyDrive/공모전/submissions/val_proba1_kobert0409', proba_digit1_valid)\n","np.save('/content/drive/MyDrive/공모전/submissions/val_proba2_kober0t0409', proba_digit2_valid)\n","np.save('/content/drive/MyDrive/공모전/submissions/val_proba3_kobert0409', proba_digit3_valid)"]},{"cell_type":"markdown","metadata":{"id":"WhvuKKtJGcRr"},"source":["### Submisssion"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6835,"status":"ok","timestamp":1649657229174,"user":{"displayName":"권유진","userId":"17694849594474805342"},"user_tz":-540},"id":"XqD36piFKqvt","outputId":"aa89eec2-62d7-4d5b-b9bc-eae045049287"},"outputs":[],"source":["test_list = []\n","for q in file1['sen']:\n","    data = [q, '0']\n","    test_list.append(data)\n","\n","#토큰화 및 dataload\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","sub_set = BERTDataset(test_list, 0, 1, tok, max_len, True, False)\n","sub_dataloader = torch.utils.data.DataLoader(sub_set, batch_size=batch_size, num_workers=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5a4I9kSgGb-x"},"outputs":[],"source":["batch_size = 16\n","\n","sub_set = sub_dataloader.dataset.sentences\n","\n","sub_dataloader = DataLoader(\n","            sub_set,\n","            sampler = SequentialSampler(sub_set),\n","            batch_size = batch_size\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fJQ70khxLn64"},"outputs":[],"source":["def predict_proba(model, dataloader):\n","    model.eval()\n","    preds = []\n","    for batch in dataloader:\n","        batch1, batch2, batch3 = tuple(t.long().to(device) for t in batch)\n","        with torch.no_grad():\n","            pred = model(batch1, batch2, batch3)\n","            preds.append(pred)\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zotO_WzDHSRq"},"outputs":[],"source":["proba_digit1_sub = torch.cat(predict_proba(model1, sub_dataloader),axis=0).cpu().numpy()\n","proba_digit2_sub = torch.cat(predict_proba(model2, sub_dataloader),axis=0).cpu().numpy()\n","proba_digit3_sub = torch.cat(predict_proba(model3, sub_dataloader),axis=0).cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Z4axp9cHpoB"},"outputs":[],"source":["np.save('/content/drive/MyDrive/공모전/submissions/sub_proba1_kobert0409', proba_digit1_sub)\n","np.save('/content/drive/MyDrive/공모전/submissions/sub_proba2_kobert0409', proba_digit2_sub)\n","np.save('/content/drive/MyDrive/공모전/submissions/sub_proba3_kobert0409', proba_digit3_sub)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPYARPlUO7UbbHbaFI6hL/1","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1BC2Cd3oIQX92CxvB1qje1g3gcdg_7bvh","name":"KoBERT.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
